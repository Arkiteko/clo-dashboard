import streamlit as st
import pandas as pd
from pathlib import Path
from src.etl import ETLPipeline
from src.utils import ingest_file
from src.config import get_warehouse_config, save_warehouse_config, WarehouseConfig, StressConfig
from src.stress import run_all_scenarios


# Config
DATA_DIR = Path("data")
RAW_DIR = DATA_DIR / "0_raw"
STAGING_DIR = DATA_DIR / "1_staging"
STANDARD_DIR = DATA_DIR / "2_standard"
PUBLISHED_DIR = DATA_DIR / "3_published"

# Ensure dirs exist
RAW_DIR.mkdir(parents=True, exist_ok=True)
PUBLISHED_DIR.mkdir(parents=True, exist_ok=True)

st.set_page_config(page_title="CLO Warehouse Platform", layout="wide")

st.title("CLO Warehouse Platform")

tabs = st.tabs(["Global Portfolio", "Warehouse Analytics", "Stress Testing", "Tape Ingestion", "Admin Settings"])

# Load all published data globally for use in tabs
files = list(PUBLISHED_DIR.glob("*.parquet"))
df_all = pd.DataFrame()
from datetime import datetime

if files:
    dfs = []
    for f in files:
        d = pd.read_parquet(f)
        name = f.stem # e.g. 20230101_120000_Warehouse_Alpha
        
        parts = name.split("_")
        
        # Default fallback
        data_date = datetime.now()
        upload_ts = "000000"
        warehouse_name = "Unknown"
        
        # New Format: YYYYMMDD_HHMMSS_Name...
        if len(parts) >= 3 and len(parts[0])==8 and len(parts[1])==6:
             try:
                 data_date = datetime.strptime(parts[0], "%Y%m%d")
                 upload_ts = parts[1]
                 warehouse_name = "_".join(parts[2:]).replace(".parquet", "")
                 # Remove 'Tape' suffix if present (generated by dummy script)
                 warehouse_name = warehouse_name.replace("_Tape", "")
             except:
                 pass
        else:
             # Legacy/Fallback parsing (try to recover old files)
             try:
                 ts_str = parts[0]
                 if len(ts_str) == 8:
                      data_date = datetime.strptime(ts_str, "%Y%m%d")
                 if "Warehouse" in parts:
                     idx = parts.index("Warehouse")
                     warehouse_name = "_".join(parts[idx:idx+2])
             except:
                 pass

        d["warehouse_source"] = warehouse_name
        d["data_date"] = data_date
        d["upload_ts"] = upload_ts # useful for sorting
        d["data_date"] = pd.to_datetime(d["data_date"])
        
        dfs.append(d)
    
    if dfs:
        df_raw = pd.concat(dfs, ignore_index=True)
        # Deduplication Logic
        # Sort by Upload Timestamp ascending, then drop duplicates keeping last
        # This means if we have 2 files for 2023-01-01, we keep the one uploaded later.
        df_all = df_raw.sort_values("upload_ts").drop_duplicates(
             subset=["warehouse_source", "data_date", "asset_id"], # Granular dedup? No, usually replace entire tape.
             keep="last"
        )
        # Actually, typically we replace the ENTIRE DAY's tape. 
        # But here we are concatenating asset-level rows. 
        # If we just uploaded a new file for the SAME DATE, we probably want to ignore the old file's rows entirely.
        
        # Better approach: Filter at FILE level or bulk drop.
        # Let's do: Group keys (Warehouse, Date) -> find max TS. Filter source DFs.
        # But since we already loaded, let's just group by (Warehouse, Date) and keep rows from the max TS.
        
        # 1. Identify valid (Warehouse, Date, TS) tuples
        versions = df_raw[["warehouse_source", "data_date", "upload_ts"]].drop_duplicates()
        # 2. Find max TS for each (Warehouse, Date)
        latest_versions = versions.sort_values("upload_ts").groupby(["warehouse_source", "data_date"]).tail(1)
        
        # 3. Join back to keep only those rows
        # A simple merge on all 3 columns acts as a filter
        df_all = df_raw.merge(latest_versions, on=["warehouse_source", "data_date", "upload_ts"], how="inner")


with tabs[0]:
    st.header("Global Portfolio Overview")
    
    if df_all.empty:
        st.info("No published data found. Please ingest some tapes.")
    else:
        # Filter for LATEST snapshot per warehouse (all assets from latest date)
        latest_dates = df_all.groupby("warehouse_source")["data_date"].transform("max")
        df_latest = df_all[df_all["data_date"] == latest_dates].copy()
        
        # Enrich with Strategy Type from Config
        # We need to look up config for each filtered row
        def get_type(row):
            c = get_warehouse_config(row["warehouse_source"])
            return c.warehouse_type
            
        df_latest["Strategy"] = df_latest.apply(get_type, axis=1)
        
        # Overall Metrics (Latest)
        total_funded = df_latest.groupby("warehouse_source").apply(lambda x: x["par_amount"].sum()).sum()
        
        # W.Avg Price (Global across latest)
        global_par = df_latest["par_amount"].sum()
        weighted_avg_price = (df_latest["par_amount"] * df_latest["market_price"]).sum() / global_par if global_par > 0 else 0
        total_assets = len(df_latest)
        
        # Global WAS / WAL / CCC
        # Need to handle missing cols if old data, but we just regen'd
        if "spread" in df_latest.columns:
            weighted_avg_spread = (df_latest["par_amount"] * df_latest["spread"]).sum() / global_par if global_par > 0 else 0
        else:
            weighted_avg_spread = 0
            
        if "maturity_date" in df_latest.columns:
            today_date = pd.to_datetime(datetime.now())
            df_latest["years_to_mat"] = (df_latest["maturity_date"] - today_date).dt.days / 365.0
            weighted_avg_life = (df_latest["par_amount"] * df_latest["years_to_mat"]).sum() / global_par if global_par > 0 else 0
        else:
            weighted_avg_life = 0
            
        ccc_exposure = 0
        if "rating_moodys" in df_latest.columns:
             ccc_exposure = df_latest[df_latest["rating_moodys"].str.contains("Caa") | df_latest["rating_moodys"].str.contains("C")]["par_amount"].sum()
        ccc_pct = ccc_exposure / total_funded if total_funded > 0 else 0

        c1, c2, c3, c4 = st.columns(4)
        c1.metric("Total Funded Exposure", f"${total_funded/1_000_000:,.1f}M")
        c2.metric("Portfolio W.Avg Price", f"{weighted_avg_price:.2f}")
        c3.metric("W.Avg Spread (WAS)", f"{weighted_avg_spread:.0f} bps")
        c4.metric("W.Avg Life (WAL)", f"{weighted_avg_life:.2f} yrs")
        
        c5, c6, c7, c8 = st.columns(4)
        c5.metric("Total Assets", total_assets)
        c6.metric("Active Warehouses", df_latest["warehouse_source"].nunique())
        c7.metric("Global CCC %", f"{ccc_pct:.2%}")
        
        st.divider()
        st.subheader("Exposure by Strategy")
        
        # Group by Strategy
        strat_stats = []
        if "Strategy" in df_latest.columns:
            for strat, g in df_latest.groupby("Strategy"):
                s_fund = g.groupby("warehouse_source").apply(lambda x: x["par_amount"].sum()).sum()
                s_price = (g["par_amount"] * g["market_price"]).sum() / s_fund if s_fund > 0 else 0
                s_was = (g["par_amount"] * g["spread"]).sum() / s_fund if s_fund > 0 else 0
                s_count = g["warehouse_source"].nunique()
                strat_stats.append({
                    "Strategy": strat,
                    "Funded Exposure": s_fund,
                    "W.Avg Price": s_price,
                    "WAS": s_was,
                    "Warehouses": s_count
                })
            
        if strat_stats:
            df_strat = pd.DataFrame(strat_stats)
            
            # Show Metrics Columns
            cols = st.columns(len(strat_stats))
            for idx, row in df_strat.iterrows():
                with cols[idx]:
                    st.metric(f"{row['Strategy']}", f"${row['Funded Exposure']/1e6:,.1f}M", f"WAS: {row['WAS']:.0f} bps")
                    
            # st.bar_chart(df_strat.set_index("Strategy")["Funded Exposure"])
        
        st.divider()
        
        col_charts1, col_charts2 = st.columns(2)
        
        with col_charts1:
            st.subheader("Global Industry Concentration")
            if "industry_gics" in df_latest.columns:
                ind_exp = df_latest.groupby("industry_gics")["par_amount"].sum().sort_values(ascending=False).head(10)
                st.bar_chart(ind_exp)
                
        with col_charts2:
            st.subheader("Global Rating Distribution")
            if "rating_moodys" in df_latest.columns:
                rtg_exp = df_latest.groupby("rating_moodys")["par_amount"].sum()
                # Sort?
                st.bar_chart(rtg_exp)
        
        st.subheader("Top 20 Issuers (Global)")
        if "issuer_name" in df_latest.columns:
            iss_exp = df_latest.groupby("issuer_name")["par_amount"].sum().sort_values(ascending=False).head(20)
            st.dataframe(iss_exp.reset_index().rename(columns={"par_amount": "Total Exposure"}), use_container_width=True)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # WAREHOUSE SUMMARY TABLE
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.divider()
        st.subheader("Warehouse Comparison")

        wh_summary_rows = []
        today_dt = pd.to_datetime(datetime.now())
        for wh_name, g in df_latest.groupby("warehouse_source"):
            cfg = get_warehouse_config(wh_name)
            funded = g["par_amount"].sum()
            w_price = (g["par_amount"] * g["market_price"]).sum() / funded if funded > 0 else 0
            w_was = (g["par_amount"] * g["spread"]).sum() / funded if funded > 0 else 0 if "spread" in g.columns else 0

            if "maturity_date" in g.columns:
                g_wal = (g["par_amount"] * ((pd.to_datetime(g["maturity_date"]) - today_dt).dt.days / 365.0)).sum() / funded if funded > 0 else 0
            else:
                g_wal = 0

            # Estimated OC & utilization
            est_debt = funded * (w_price / 100) * cfg.advance_rate
            est_oc = funded / est_debt if est_debt > 0 else 0
            util = est_debt / cfg.max_facility_amount if cfg.max_facility_amount > 0 else 0

            # CCC
            if "rating_moodys" in g.columns:
                ccc_par = g[g["rating_moodys"].str.contains("Caa|C", na=False)]["par_amount"].sum()
            else:
                ccc_par = 0
            ccc = ccc_par / funded if funded > 0 else 0

            wh_summary_rows.append({
                "Warehouse": wh_name,
                "Type": cfg.warehouse_type,
                "Funded ($M)": round(funded / 1e6, 2),
                "W.Avg Price": round(w_price, 2),
                "WAS (bps)": round(w_was, 0),
                "WAL (yrs)": round(g_wal, 2),
                "Est. OC Ratio": f"{est_oc:.2%}",
                "Utilization": f"{util:.1%}",
                "CCC %": f"{ccc:.1%}",
                "Assets": len(g),
            })

        if wh_summary_rows:
            df_wh_summary = pd.DataFrame(wh_summary_rows)
            st.dataframe(df_wh_summary, use_container_width=True, hide_index=True)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # COMPLIANCE HEATMAP
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.divider()
        st.subheader("Compliance Status")

        compliance_rows = []
        for wh_name, g in df_latest.groupby("warehouse_source"):
            cfg = get_warehouse_config(wh_name)
            funded = g["par_amount"].sum()
            w_price = (g["par_amount"] * g["market_price"]).sum() / funded if funded > 0 else 0

            # OC
            est_debt = funded * (w_price / 100) * cfg.advance_rate
            est_oc = funded / est_debt if est_debt > 0 else 0
            oc_status = "âœ…" if est_oc >= cfg.oc_trigger_pct else "ðŸ”´"

            # CCC
            if "rating_moodys" in g.columns:
                ccc_par = g[g["rating_moodys"].str.contains("Caa|C", na=False)]["par_amount"].sum()
            else:
                ccc_par = 0
            ccc_pct = ccc_par / funded if funded > 0 else 0
            ccc_status = "âœ…" if ccc_pct <= 0.075 else "ðŸ”´"

            # Industry concentration
            if "industry_gics" in g.columns:
                max_ind_pct = g.groupby("industry_gics")["par_amount"].sum().max() / funded if funded > 0 else 0
            else:
                max_ind_pct = 0
            ind_status = "âœ…" if max_ind_pct <= cfg.concentration_limit_industry else "âš ï¸"

            compliance_rows.append({
                "Warehouse": wh_name,
                "OC Ratio": f"{est_oc:.2%}",
                "OC Trigger": f"{cfg.oc_trigger_pct:.0%}",
                "OC Status": oc_status,
                "CCC %": f"{ccc_pct:.1%}",
                "CCC Limit": "7.5%",
                "CCC Status": ccc_status,
                "Max Industry": f"{max_ind_pct:.1%}",
                "Ind. Limit": f"{cfg.concentration_limit_industry:.0%}",
                "Ind. Status": ind_status,
            })

        if compliance_rows:
            df_compliance = pd.DataFrame(compliance_rows)
            st.dataframe(df_compliance, use_container_width=True, hide_index=True)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # LIEN TYPE & FACILITY MIX
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.divider()
        st.subheader("Portfolio Composition")

        col_lien, col_flags = st.columns(2)

        with col_lien:
            st.markdown("**Lien Type Breakdown**")
            if "lien_type" in df_latest.columns:
                lien_by_wh = df_latest.groupby(["warehouse_source", "lien_type"])["par_amount"].sum().unstack(fill_value=0)
                st.bar_chart(lien_by_wh)
            else:
                st.info("Lien type data not available.")

        with col_flags:
            st.markdown("**Portfolio Flags**")
            total_par = df_latest["par_amount"].sum()
            if total_par > 0:
                cov_lite_pct = df_latest[df_latest["is_cov_lite"] == True]["par_amount"].sum() / total_par if "is_cov_lite" in df_latest.columns else 0
                pik_pct = df_latest[df_latest["is_pik"] == True]["par_amount"].sum() / total_par if "is_pik" in df_latest.columns else 0
                default_pct = df_latest[df_latest["is_defaulted"] == True]["par_amount"].sum() / total_par if "is_defaulted" in df_latest.columns else 0

                f1, f2, f3 = st.columns(3)
                f1.metric("Cov-Lite %", f"{cov_lite_pct:.1%}")
                f2.metric("PIK %", f"{pik_pct:.1%}")
                f3.metric("Defaulted %", f"{default_pct:.1%}", delta_color="inverse" if default_pct > 0 else "off")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # MATURITY PROFILE
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.divider()
        st.subheader("Maturity Profile")

        if "maturity_date" in df_latest.columns:
            df_mat = df_latest.copy()
            df_mat["maturity_year"] = pd.to_datetime(df_mat["maturity_date"]).dt.year
            current_year = datetime.now().year
            # Bucket anything beyond current_year + 5 as "Later"
            df_mat["maturity_bucket"] = df_mat["maturity_year"].apply(
                lambda y: str(y) if y <= current_year + 5 else f"{current_year + 6}+"
            )
            mat_exp = df_mat.groupby("maturity_bucket")["par_amount"].sum().sort_index()
            st.bar_chart(mat_exp)
        else:
            st.info("Maturity date data not available.")


with tabs[1]:
    st.header("Warehouse Analytics")
    
    if df_all.empty:
        st.info("No data available.")
    else:
        # Selector
        wh_list = sorted(df_all["warehouse_source"].unique())
        selected_wh = st.selectbox("Select Warehouse", wh_list, key="wh_select_analytics")
        
        # Full history for trends
        df_wh_history = df_all[df_all["warehouse_source"] == selected_wh].copy().sort_values("data_date")
        
        # Latest snapshot for current metrics
        latest_date = df_wh_history["data_date"].max()
        df_wh = df_wh_history[df_wh_history["data_date"] == latest_date].copy()
        
        config = get_warehouse_config(selected_wh)
        
        # Metrics Calculation (Latest)
        wh_funded = df_wh["par_amount"].sum()
        wh_price = (df_wh["par_amount"] * df_wh["market_price"]).sum() / wh_funded if wh_funded > 0 else 0
        
        # New Metrics: WAS and WAL
        # WAS = Weighted Average Spread
        wh_was = (df_wh["par_amount"] * df_wh["spread"]).sum() / wh_funded if wh_funded > 0 else 0
        
        # WAL = Weighted Average Life (Years from Today to Maturity)
        # simplistic day count / 365
        today_date = pd.to_datetime(latest_date)
        df_wh["years_to_mat"] = (df_wh["maturity_date"] - today_date).dt.days / 365.0
        wh_wal = (df_wh["par_amount"] * df_wh["years_to_mat"]).sum() / wh_funded if wh_funded > 0 else 0
        
        # Simulated Snapshot Inputs
        st.markdown(f"#### ðŸŸ¢ Compliance & Metrics (As of {latest_date.date()}) [{config.warehouse_type}]")
        
        # Calc Implied Debt if not entered
        implied_debt = wh_funded * (wh_price/100) * config.advance_rate
        
        # Inputs for Calc - these define the "Current State" for the snapshot
        c_snap1, c_snap2 = st.columns(2)
        debt_outstanding = c_snap1.number_input("Debt Outstanding (Snapshot)", value=implied_debt, help="Enter actual debt from report")
        cash_balance = c_snap2.number_input("Cash Balance", value=0.0)
        
        # OC Calculation
        total_collateral_par = wh_funded
        numerator = total_collateral_par + cash_balance
        denominator = debt_outstanding if debt_outstanding > 0 else 1.0
        
        current_oc = numerator / denominator
        
        # Display Key Metrics Row
        m1, m2, m3, m4 = st.columns(4)
        m1.metric("Facility Utilization", f"{(debt_outstanding / config.max_facility_amount)*100:.1f}%", f"Limit: ${config.max_facility_amount/1e6:.0f}M")
        
        oc_delta = current_oc - config.oc_trigger_pct
        m2.metric("OC Ratio", f"{current_oc:.2%}", f"{oc_delta:.2%} vs Trig ({config.oc_trigger_pct:.0%})", delta_color="normal" if oc_delta >= 0 else "inverse")
        
        m3.metric("Equity (NAV)", f"${(numerator - debt_outstanding)/1e6:,.2f}M")
        m4.metric("W.Avg Price", f"{wh_price:.2f}")

        # Secondary Metrics Row
        m5, m6, m7, m8 = st.columns(4)
        m5.metric("W.Avg Spread (WAS)", f"{wh_was:.0f} bps")
        m6.metric("W.Avg Life (WAL)", f"{wh_wal:.2f} yrs")
        
        # Calc CCC
        ccc_exposure = df_wh[df_wh["rating_moodys"].str.contains("Caa") | df_wh["rating_moodys"].str.contains("C")]["par_amount"].sum()
        ccc_pct = ccc_exposure / wh_funded if wh_funded > 0 else 0
        m7.metric("CCC Exposure", f"{ccc_pct:.1%}", "Limit: 7.5%", delta_color="inverse" if ccc_pct > 0.075 else "normal")
        
        m8.metric("Asset Count", len(df_wh))

        st.divider()
        
        # Tabs for detailed analysis
        subtabs = st.tabs(["Asset Quality", "Trends", "Portfolio Composition"])
        
        with subtabs[0]:
            st.subheader("Credit Quality")
            
            c_qual1, c_qual2 = st.columns(2)
            
            with c_qual1:
                st.markdown("**Rating Distribution**")
                if "rating_moodys" in df_wh.columns:
                    # Sort ratings logic? simpler to just count for now
                    rtg_exp = df_wh.groupby("rating_moodys")["par_amount"].sum()
                    st.bar_chart(rtg_exp)
            
            with c_qual2:
                st.markdown("**Rating Migration (vs Original)**")
                if "original_rating_moodys" in df_wh.columns:
                    # Simple table
                    df_mig = df_wh[["asset_id", "issuer_name", "original_rating_moodys", "rating_moodys", "par_amount"]].copy()
                    df_mig["Downgraded"] = df_mig.apply(lambda x: x["rating_moodys"] != x["original_rating_moodys"], axis=1) # naive check
                    st.dataframe(df_mig[df_mig["Downgraded"]], hide_index=True)
                    
        with subtabs[1]:
            st.subheader("Historical Trends")
            # Prepare Trend Data
            trend_data = []
            for d, g in df_wh_history.groupby("data_date"):
                 fnd = g["par_amount"].sum()
                 px = (g["par_amount"] * g["market_price"]).sum() / fnd if fnd > 0 else 0
                 
                 # Estimate simple OC
                 est_debt = fnd * (px/100) * config.advance_rate
                 est_oc = fnd / est_debt if est_debt > 0 else 0
                 
                 trend_data.append({
                     "Date": d,
                     "Funded Exposure": fnd,
                     "W.Avg Price": px,
                     "Est. OC%": est_oc
                 })
            
            df_trend = pd.DataFrame(trend_data).set_index("Date")
            
            t1, t2 = st.columns(2)
            with t1:
                st.line_chart(df_trend["Funded Exposure"])
            with t2:
                st.line_chart(df_trend["W.Avg Price"])

        with subtabs[2]:
            st.subheader("Concentration Analysis")
            
            c_conc1, c_conc2 = st.columns(2)
            with c_conc1:
                 st.write("**Top Industries**")
                 ind_exp = df_wh.groupby("industry_gics")["par_amount"].sum().sort_values(ascending=False).head(5)
                 st.bar_chart(ind_exp)
                 
            with c_conc2:
                 st.write("**Top Obligors**")
                 iss_exp = df_wh.groupby("issuer_name")["par_amount"].sum().sort_values(ascending=False).head(5)
                 st.bar_chart(iss_exp)
            
            st.markdown("---")
            st.dataframe(df_wh[["asset_id", "issuer_name", "par_amount", "market_price", "spread", "maturity_date", "rating_moodys"]], use_container_width=True)


with tabs[2]:
    st.header("Stress Testing / SVar")

    if df_all.empty:
        st.info("No data available. Please ingest tapes first.")
    else:
        wh_list_stress = sorted(df_all["warehouse_source"].unique())
        selected_wh_stress = st.selectbox("Select Warehouse", wh_list_stress, key="wh_select_stress")

        # Get latest snapshot for selected warehouse
        df_wh_stress_all = df_all[df_all["warehouse_source"] == selected_wh_stress].copy()
        latest_date_stress = df_wh_stress_all["data_date"].max()
        df_wh_stress = df_wh_stress_all[df_wh_stress_all["data_date"] == latest_date_stress].copy()

        config_stress = get_warehouse_config(selected_wh_stress)
        s_cfg = config_stress.stress_config

        # Optional debt override
        wh_funded_stress = df_wh_stress["par_amount"].sum()
        wh_price_stress = (df_wh_stress["par_amount"] * df_wh_stress["market_price"]).sum() / wh_funded_stress if wh_funded_stress > 0 else 100
        implied_debt_stress = wh_funded_stress * (wh_price_stress / 100) * config_stress.advance_rate

        col_debt, col_cash = st.columns(2)
        debt_input = col_debt.number_input("Debt Outstanding", value=implied_debt_stress, key="stress_debt")
        cash_input = col_cash.number_input("Cash Balance", value=0.0, key="stress_cash")

        run_stress = st.button("Run Stress Analysis", type="primary")

        if run_stress:
            with st.spinner("Running stress scenarios..."):
                results = run_all_scenarios(
                    df_wh_stress, config_stress, s_cfg,
                    debt_outstanding=debt_input, cash_balance=cash_input
                )

            # â”€â”€ Row 1: Aggregate Summary â”€â”€
            st.divider()
            st.subheader("Aggregate Stress Summary")

            a1, a2, a3, a4 = st.columns(4)
            a1.metric(
                "Total Stressed Loss",
                f"${results.total_stressed_loss / 1e6:,.2f}M",
                f"-{results.total_stressed_loss / results.total_par:.1%} of par" if results.total_par > 0 else ""
            )
            a2.metric(
                "Stressed OC Ratio",
                f"{results.stressed_oc:.2%}",
                f"{results.stressed_oc - results.base_oc:.2%} vs base",
                delta_color="inverse"
            )
            if results.oc_breach:
                a3.metric("OC Breach", "YES", f"Trigger: {results.oc_trigger:.0%}", delta_color="inverse")
            else:
                a3.metric("OC Breach", "NO", f"Trigger: {results.oc_trigger:.0%}", delta_color="off")
            a4.metric(
                "Stressed CCC %",
                f"{results.stressed_ccc_pct:.1%}",
                "BREACH" if results.ccc_breach else "Within limit",
                delta_color="inverse" if results.ccc_breach else "off"
            )

            # â”€â”€ Row 2: Scenario Breakdown Table â”€â”€
            st.divider()
            st.subheader("Scenario Breakdown")

            scenario_rows = []
            for s in results.scenarios:
                scenario_rows.append({
                    "Scenario": s.name,
                    "Loss ($M)": round(s.loss_dollars / 1e6, 2),
                    "Loss (%)": f"{s.loss_pct:.2%}",
                    "Key Detail": s.detail,
                })
            df_scenario = pd.DataFrame(scenario_rows)
            st.dataframe(df_scenario, use_container_width=True, hide_index=True)

            # â”€â”€ Row 3: Charts + Comparison â”€â”€
            st.divider()
            col_chart, col_compare = st.columns(2)

            with col_chart:
                st.markdown("**Loss by Scenario**")
                chart_data = pd.DataFrame({
                    "Scenario": [s.name for s in results.scenarios],
                    "Loss ($M)": [s.loss_dollars / 1e6 for s in results.scenarios]
                }).set_index("Scenario")
                st.bar_chart(chart_data)

            with col_compare:
                st.markdown("**Stressed vs Unstressed**")
                c1, c2 = st.columns(2)
                c1.metric("Base OC", f"{results.base_oc:.2%}")
                c2.metric("Stressed OC", f"{results.stressed_oc:.2%}", f"{results.stressed_oc - results.base_oc:.2%}", delta_color="inverse")

                # Base CCC
                base_ccc_par = df_wh_stress[df_wh_stress["rating_moodys"].str.contains("Caa|C", na=False)]["par_amount"].sum()
                base_ccc_pct = base_ccc_par / results.total_par if results.total_par > 0 else 0
                c3, c4 = st.columns(2)
                c3.metric("Base CCC %", f"{base_ccc_pct:.1%}")
                c4.metric("Stressed CCC %", f"{results.stressed_ccc_pct:.1%}", f"{results.stressed_ccc_pct - base_ccc_pct:+.1%}", delta_color="inverse" if results.ccc_breach else "off")

                # NAV
                base_nav = (results.total_par + cash_input) - debt_input
                stressed_nav = (results.total_par - results.total_stressed_loss + cash_input) - debt_input
                c5, c6 = st.columns(2)
                c5.metric("Base NAV", f"${base_nav / 1e6:,.2f}M")
                c6.metric("Stressed NAV", f"${stressed_nav / 1e6:,.2f}M", f"${(stressed_nav - base_nav) / 1e6:,.2f}M", delta_color="inverse")

            # â”€â”€ Row 4: Asset-Level Detail â”€â”€
            st.divider()
            st.subheader("Asset-Level Stress Detail")

            for s in results.scenarios:
                if s.asset_level is not None and not s.asset_level.empty:
                    with st.expander(f"{s.name} â€” Asset Detail"):
                        display_df = s.asset_level.copy()
                        # Format loss column
                        if "loss" in display_df.columns:
                            display_df = display_df.sort_values("loss", ascending=False)
                        st.dataframe(display_df, use_container_width=True, hide_index=True)


with tabs[3]:
    st.markdown("### Data Tape Ingestion & Validation")

    uploaded_file = st.file_uploader("Drop Standard Template (Excel)", type=["xlsx"])
    warehouse_name = st.selectbox("Select Warehouse Name for Ingestion", ["Warehouse_Alpha", "Warehouse_Beta", "Warehouse_Gamma"])
    as_of_date = st.date_input("As Of Date")
    
    process_btn = st.button("Process Tape")

    if uploaded_file and process_btn:
        with st.spinner("Ingesting and Validating..."):
            # 1. Ingest
            raw_path = ingest_file(uploaded_file, RAW_DIR, warehouse_name)
            st.success(f"File saved: {raw_path.name}")
            
            # 2. Run ETL
            pipeline = ETLPipeline(RAW_DIR, STAGING_DIR, STANDARD_DIR)
            df, issues = pipeline.process_tape(raw_path)
            
            if df is not None:
                # Display Results
                st.divider()
                st.subheader("Validation Report")
                
                hard_errors = [i for i in issues if i.severity == "HARD"]
                soft_warns = [i for i in issues if i.severity == "SOFT"]
                
                c1, c2 = st.columns(2)
                c1.metric("Hard Errors", len(hard_errors), delta_color="inverse" if hard_errors else "off")
                c2.metric("Warnings", len(soft_warns), delta_color="normal")
                
                if hard_errors:
                    st.error("Blocking Issues Found - Data NOT Published:")
                    for e in hard_errors:
                        st.write(f"- {e.message} (Row IDs: {e.row_id})")
                
                if soft_warns:
                    st.warning("Warnings:")
                    for w in soft_warns:
                         st.write(f"- {w.message}")
                         
                if not hard_errors:
                    st.success("Published Successfully!")
                    st.cache_data.clear()
            else:
                st.error("Failed to parse file.")

    st.divider()
    st.markdown("### Load History")
    
    if df_all.empty:
        st.info("No load history.")
    else:
        # Show what is currently loaded/active
        # We can also show 'Overwritten' files if we scanned the raw dir, but showing the Active set is good for now.
        # Actually user wants 'History' so let's show the deduplicated active view + maybe a count of versions?
        
        # Simple table of the ACTIVE dataset
        hist_df = df_all.groupby(["warehouse_source", "data_date"]).agg(
            Assets=("asset_id", "count"),
            Total_Funded=("par_amount", "sum"),
            Last_Updated=("data_date", "max") # Placeholder, really want upload time
        ).reset_index().sort_values(["warehouse_source", "data_date"], ascending=[True, False])
        
        # Format for display
        hist_df["Total_Funded"] = hist_df["Total_Funded"].apply(lambda x: f"${x/1e6:,.2f}M")
        
        st.dataframe(hist_df, use_container_width=True)


with tabs[4]:
    st.header("Admin Settings")
    st.info("Configure Limits and Triggers for each warehouse here.")
    
    if df_all.empty:
         st.warning("No warehouses found. Please ingest data first.")
    else:
        wh_list = sorted(df_all["warehouse_source"].unique())
        selected_wh_admin = st.selectbox("Select Warehouse to Configure", wh_list, key="wh_select_admin")
        
        config = get_warehouse_config(selected_wh_admin)
        
        with st.form("admin_config_form"):
            st.subheader(f"Configuration for: {selected_wh_admin}")

            # Type Selector
            new_type = st.selectbox("Warehouse Type", ["BSL", "Middle Market"], index=0 if config.warehouse_type=="BSL" else 1)

            c_adm1, c_adm2 = st.columns(2)

            with c_adm1:
                st.markdown("#### Facility Limits")
                new_max = st.number_input("Max Facility Size ($)", value=float(config.max_facility_amount))
                new_adv = st.slider("Advance Rate", 0.0, 1.0, value=float(config.advance_rate))

            with c_adm2:
                st.markdown("#### Compliance Triggers")
                new_oc = st.number_input("Min OC Ratio Trigger (decimal)", value=float(config.oc_trigger_pct), step=0.01, help="e.g. 1.25 for 125%")
                new_conc = st.slider("Max Industry Concentration", 0.0, 1.0, value=float(config.concentration_limit_industry))

            # â”€â”€ Stress Parameters â”€â”€
            st.divider()
            st.subheader("Stress Test Parameters")
            sc = config.stress_config

            st_col1, st_col2, st_col3 = st.columns(3)

            with st_col1:
                st.markdown("**Price Shock Haircuts (pts)**")
                sp_ig = st.number_input("IG", value=float(sc.price_shock_ig), step=0.5, key="sp_ig")
                sp_bb = st.number_input("BB", value=float(sc.price_shock_bb), step=0.5, key="sp_bb")
                sp_b = st.number_input("B", value=float(sc.price_shock_b), step=0.5, key="sp_b")
                sp_ccc = st.number_input("CCC", value=float(sc.price_shock_ccc), step=1.0, key="sp_ccc")

            with st_col2:
                st.markdown("**Default Rates (CDR)**")
                cdr_ig = st.number_input("IG CDR", value=float(sc.cdr_ig), step=0.005, format="%.3f", key="cdr_ig")
                cdr_bb = st.number_input("BB CDR", value=float(sc.cdr_bb), step=0.01, format="%.3f", key="cdr_bb")
                cdr_b = st.number_input("B CDR", value=float(sc.cdr_b), step=0.01, format="%.3f", key="cdr_b")
                cdr_ccc = st.number_input("CCC CDR", value=float(sc.cdr_ccc), step=0.01, format="%.3f", key="cdr_ccc")

                st.markdown("**Recovery Rates**")
                rec_1l = st.number_input("1L Recovery", value=float(sc.recovery_1l), step=0.05, format="%.2f", key="rec_1l")
                rec_2l = st.number_input("2L Recovery", value=float(sc.recovery_2l), step=0.05, format="%.2f", key="rec_2l")
                rec_un = st.number_input("Unsecured Recovery", value=float(sc.recovery_unsecured), step=0.05, format="%.2f", key="rec_un")

            with st_col3:
                st.markdown("**Spread Shocks (bps)**")
                ss_ig = st.number_input("IG Spread", value=float(sc.spread_shock_ig), step=10.0, key="ss_ig")
                ss_bb = st.number_input("BB Spread", value=float(sc.spread_shock_bb), step=25.0, key="ss_bb")
                ss_b = st.number_input("B Spread", value=float(sc.spread_shock_b), step=25.0, key="ss_b")
                ss_ccc = st.number_input("CCC Spread", value=float(sc.spread_shock_ccc), step=50.0, key="ss_ccc")

                st.markdown("**Migration & Concentration**")
                mig_rate = st.number_input("Migration Rate", value=float(sc.migration_rate), step=0.05, format="%.2f", key="mig_rate")
                conc_n = st.number_input("Top N Obligors", value=int(sc.concentration_top_n), step=1, key="conc_n")

            if st.form_submit_button("Save Configuration"):
                new_stress = StressConfig(
                    price_shock_ig=sp_ig, price_shock_bb=sp_bb,
                    price_shock_b=sp_b, price_shock_ccc=sp_ccc,
                    cdr_ig=cdr_ig, cdr_bb=cdr_bb, cdr_b=cdr_b, cdr_ccc=cdr_ccc,
                    recovery_1l=rec_1l, recovery_2l=rec_2l, recovery_unsecured=rec_un,
                    spread_shock_ig=ss_ig, spread_shock_bb=ss_bb,
                    spread_shock_b=ss_b, spread_shock_ccc=ss_ccc,
                    migration_rate=mig_rate, concentration_top_n=int(conc_n),
                )
                new_cfg = WarehouseConfig(
                    max_facility_amount=new_max,
                    advance_rate=new_adv,
                    oc_trigger_pct=new_oc,
                    concentration_limit_industry=new_conc,
                    warehouse_type=new_type,
                    stress_config=new_stress,
                )
                save_warehouse_config(selected_wh_admin, new_cfg)
                st.success(f"Settings saved for {selected_wh_admin}")
                st.rerun()
